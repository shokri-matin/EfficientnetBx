{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FP-CIFAR10.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yk8KGD6A8pK"
      },
      "source": [
        "## Final Project - CIFAR10\n",
        "\n",
        "1.   Using EfficentNetB0 to extract rich features\n",
        "2.   Using dense neural network to clasify our classes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjDz9fttPrHR"
      },
      "source": [
        "import keras\n",
        "import matplotlib\n",
        "from keras import datasets\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "import numpy as np\n",
        "import random\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-UeHWkkB8IH"
      },
      "source": [
        "\n",
        "1.   Load CIFAR10 Dataset using Keras library \n",
        "2.   Apply the augmentation on training data\n",
        "3.   Use to_categorical method to change data labels to one-hot form\n",
        "\n",
        "Note: For EfficientNetB0 input data should range [0, 255]. Normalization is included as part of the model, so our data without preprossening is already range [0, 255]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me0nAXw8ptPE"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rotation_range=5,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "train_datagen.fit(x_train)\n",
        "\n",
        "test_datagen = ImageDataGenerator()\n",
        "test_datagen.fit(x_test)\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1It_vkooG3MT"
      },
      "source": [
        "Download and set EfficientNetB0 as pretrain networks\n",
        "\n",
        "1.   We set include_top = false for both models becuase we want to those for feature extacting\n",
        "2.   We consider Imagenet as an initial weight\n",
        "\n",
        "Note: We know EfficientNetB0 were trained on ImageNet dataset that each data has 224 * 224 * 3 dimensions so we needed to increase CIFAR10's size of dimensionality. Because of memory exception in colab, we decided to increase that 4 times (128, 128, 3) by Upsamplaing in our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHZu9OHXp2G2"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, UpSampling2D, GlobalAveragePooling2D, Flatten, Concatenate\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Model\n",
        "\n",
        "efficient_model = EfficientNetB0(include_top=False, weights=\"imagenet\", input_tensor=None, input_shape=(128, 128, 3))\n",
        "\n",
        "for layer in efficient_model.layers:\n",
        "    if isinstance(layer, BatchNormalization):\n",
        "        layer.trainable = True\n",
        "    else: \n",
        "        layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVZAGRkfp-o3"
      },
      "source": [
        "# Model configuration\n",
        "batch_size = 32\n",
        "loss_function = categorical_crossentropy\n",
        "num_classes = 10\n",
        "\n",
        "eff_model = Sequential()\n",
        "eff_model.add(UpSampling2D(input_shape=(32, 32, 3)))\n",
        "eff_model.add(UpSampling2D())\n",
        "eff_model.add(efficient_model)\n",
        "eff_model.add(GlobalAveragePooling2D())\n",
        "eff_model.add(Dense(512, activation='relu'))\n",
        "eff_model.add(Dropout(.5))\n",
        "eff_model.add(Dense(512, activation='relu'))\n",
        "eff_model.add(Dropout(.5))\n",
        "eff_model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "eff_model.compile(loss=loss_function,\n",
        "                  optimizer = Adam(),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "eff_model.summary()\n",
        "\n",
        "history = eff_model.fit(\n",
        "              train_datagen.flow(x_train,y_train, batch_size=32),\n",
        "              epochs = 10,\n",
        "              verbose = 1,\n",
        "              batch_size = batch_size,\n",
        "              validation_data = test_datagen.flow(x_test, y_test, batch_size=32)\n",
        "            )\n",
        "\n",
        "# Generate generalization metrics\n",
        "score = eff_model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss: {0} / Test accuracy: {1}'.format(score[0], score[1]))\n",
        "\n",
        "# Visualize history\n",
        "# Plot history: Loss\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Validation loss history')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()\n",
        "\n",
        "# Plot history: Accuracy\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Validation accuracy history')\n",
        "plt.ylabel('Accuracy value (%)')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}